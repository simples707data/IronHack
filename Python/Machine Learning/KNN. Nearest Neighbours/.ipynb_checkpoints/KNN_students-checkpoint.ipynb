{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh_NNSdga0Tt"
   },
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying K means (unsupervised ML ) to some basic data to explain the concept\n",
    "\n",
    "#### Code along \n",
    "\n",
    "kudos to geeks for geeks tutorial from AlindGupta - the ironhack materials are a little heavy going so we are reusing this resource to run through a visual explanation of what KNN/Kmeans is about, together in class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import additional libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the data \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation \n",
    "\n",
    "visualising the data tells us that 3 clusters looks right but visualising alone is not the full story \n",
    "\n",
    "- distortion = the avg of the squared distances from the cluster centres of the respective cluster\n",
    "- inertia = sum of squared distance of samples to their closest cluster centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the cluster model , calculate distortion and inertia \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabulate results - distortion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise results - distortion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabulate results -  inertia\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise results - inertia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What have you learnt about the application of K-means to cluster data ? \n",
    "\n",
    "Your notes here : \n",
    "\n",
    "-\n",
    "-\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means is an unsupervised learning algorithm for clustering problems, whereas KNN is a supervised learning algorithm for classification and regression problems \n",
    "\n",
    "Although both involve similar statistical techniques, you can use KNN to predict by learning from past data, to classify similar data points based on shared characteristics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwEQQELDb6xb"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1603875491273,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "aWnLG3vH7JRS",
    "outputId": "9516f2ab-069d-4e05-8bc2-25cf249cdc83"
   },
   "outputs": [],
   "source": [
    "#sticking with the healthcare for all dataset \n",
    "data = pd.read_csv('lesson_4.05_data.csv') # this file is in files_for_lesson_and_activities folder\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "executionInfo": {
     "elapsed": 735,
     "status": "ok",
     "timestamp": 1603875513231,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "drj9VcoqcYbk",
    "outputId": "286f36fc-de6f-4272-a2ca-857a3b75775f"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKoUsHvKb-Jj"
   },
   "source": [
    "## Splitting the dataset between the categorical and numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 854
    },
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1603875582490,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "-e8r0HlLcIuy",
    "outputId": "a76299ee-2389-49d1-cd00-a7046be085f6"
   },
   "outputs": [],
   "source": [
    "categoricals = data.select_dtypes(np.object)\n",
    "numericals = data.select_dtypes(np.number)\n",
    "\n",
    "\n",
    "print(\"Dataframe of numerical columns: \")\n",
    "print()\n",
    "\n",
    "display(numericals)\n",
    "\n",
    "print(\"Dataframe of categorical columns: \")\n",
    "print()\n",
    "\n",
    "display(categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets apply scaling to the numerical columns except the final column\n",
    "#which will be our y variable, average gift\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "transformer = StandardScaler().fit(numericals.iloc[:,:-1])\n",
    "scaled_numericals = transformer.transform(numericals.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RUfHPrjnV1e"
   },
   "source": [
    "Getting a dataframe with the result from the standard scaler which is a numpy array.\n",
    "\n",
    "As the numpy arrays doesn't have column names, we pick up the column names from the numerical (original) dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdscaled_numericals= pd.DataFrame(scaled_numericals,columns=numericals.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdscaled_numericals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vf4lz2XYdr3Q"
   },
   "source": [
    "## Dummifying categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "executionInfo": {
     "elapsed": 872,
     "status": "ok",
     "timestamp": 1603875629990,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "qKOdt8CHdzE0",
    "outputId": "74fcbdbc-09c7-4d14-d050-5dc16eca0228"
   },
   "outputs": [],
   "source": [
    "cat_encoded = pd.get_dummies(categoricals, drop_first=True)\n",
    "cat_encoded.head()\n",
    "\n",
    "## Alternative way to do it with OHE: However, you will have to load the corresponding libraries of sklearn.\n",
    "#encoder = OneHotEncoder(handle_unknown='error', drop='first').fit(categoricals)\n",
    "#encoded = encoder.transform(categoricals).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgMCuhjQeBce"
   },
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1603876112119,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "tg7KTwMIeE34",
    "outputId": "fb10eae2-2d8d-4080-cc42-bf77c52f965c"
   },
   "outputs": [],
   "source": [
    "full = pd.concat([pdscaled_numericals.iloc[:,:-1],cat_encoded,numericals.iloc[:,-1]],axis=1)\n",
    "print(\"The dataset size is: \", full.shape)\n",
    "print()\n",
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "executionInfo": {
     "elapsed": 1111,
     "status": "ok",
     "timestamp": 1603876264159,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "MPMo4UuUmN_Z",
    "outputId": "71c7032d-0346-4a63-aa4d-97361ee4b917"
   },
   "outputs": [],
   "source": [
    "full.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDeT3XhKnaDS"
   },
   "outputs": [],
   "source": [
    "full_x = pd.DataFrame(full,columns=full.columns.tolist()[:-1])\n",
    "full_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y. \n",
    "#X is all the features, scaled numericals and encoded categoricals which are our independent variables\n",
    "#y is the variable we seek to predict \n",
    "\n",
    "X = full_x\n",
    "y = full['AVGGIFT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0OJeDCEehAq"
   },
   "source": [
    "## Splitting data intro train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYFFV9Yzekbt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_vH-gMcn2fg"
   },
   "source": [
    "## Training the K-NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "executionInfo": {
     "elapsed": 1179,
     "status": "ok",
     "timestamp": 1603876804688,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "adAKcQjen7p-",
    "outputId": "6a5915a9-b76e-49b6-b8ac-8bd838f8a4a3"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors=4) # The keyword \"n_neighbors\" is what sets the K.\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIRgvVFyoldM"
   },
   "source": [
    "## Getting our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkCS99R2ooqu"
   },
   "outputs": [],
   "source": [
    "knn_predictions = knn_model.predict(X_test)\n",
    "# to get some predictions for y we use the X_test set. \n",
    "# we will later compare the predictions from X_test to real y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KldInhQ0o4Pb"
   },
   "source": [
    "## Getting the error metrics of our K-NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "executionInfo": {
     "elapsed": 764,
     "status": "ok",
     "timestamp": 1603877137877,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "Sowcrl3oo9zU",
    "outputId": "30f38e9c-375f-4fd0-fa90-52d3b1b6894f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "MAE = mean_absolute_error(y_test,knn_predictions)\n",
    "MSE = mean_squared_error(y_test,knn_predictions)\n",
    "RMSE = np.sqrt(MSE)\n",
    "R2 = r2_score(y_test,knn_predictions)\n",
    "\n",
    "print(\"The mean absolute error of the model in the test set is: %6.2f\" % (MAE))\n",
    "print(\"The mean squared error of the model in the test set is: %6.2f\" % (MSE))\n",
    "print(\"The root mean squared error of the model in the test set is: %6.2f\" % (RMSE))\n",
    "print(\"The R2 of the model in the test set is: %4.2f\" % (R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynNkim4Xsm_v"
   },
   "source": [
    "# Activity\n",
    "\n",
    "Train a linear model and compare the performance of both models in the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1p0NYWDsujk"
   },
   "outputs": [],
   "source": [
    "#HINT : from sklearn import linear_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONicRf-fs4gY"
   },
   "outputs": [],
   "source": [
    "#HINT : lm_predictions = lm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1603830248208,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "xVcF6EPCubeU",
    "outputId": "fe683676-7e34-498d-e348-6f08db7e1117"
   },
   "outputs": [],
   "source": [
    "#HINT : use the same metrics summary cell as above \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORt--5HK8xy3"
   },
   "source": [
    "# Activity\n",
    "\n",
    "If you think a little bit about it, the number of neighbors might be very important for our results, but will it be the only parameter that matters? Go to the documentation and check the parameters and the values they can take, pick the one you think is more relevant and change its value in the model. \n",
    "\n",
    "Hint: If K (number of neighbors) is the most important one, maybe we could measure the way these K instances affect our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 39984,
     "status": "ok",
     "timestamp": 1603834054510,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "DUeiGqd-87AQ",
    "outputId": "169385f7-c310-4ed8-eb81-8e532d9dc834"
   },
   "outputs": [],
   "source": [
    "uniform_model = KNeighborsRegressor(n_neighbors=9)\n",
    "uniform_model.fit(X_train, y_train)\n",
    "uniform_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 47478,
     "status": "ok",
     "timestamp": 1603834226382,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "wbtIM_kg9F_4",
    "outputId": "696dfac6-061c-4683-fd58-7ff1c4fc249d"
   },
   "outputs": [],
   "source": [
    "# example using parameter distance \n",
    "distance_model = KNeighborsRegressor(n_neighbors=9, weights = \"distance\")\n",
    "distance_model.fit(X_train, y_train)\n",
    "distance_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "si6-xxrM-yF9"
   },
   "source": [
    "# visualise KNN\n",
    "\n",
    "Let's visualize how KNN actually works. First of all install the mlxtend library and create a dataframe containing the two most relevant numerical variables and the target, in that order. Once you have done it sample it with n = 100, introduce that sample into this function with an arbitrary k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do this aou will need to close and halt your notebook & install mlxtend library\n",
    "\n",
    "#I had to first install pip (conda install pip) \n",
    "# then run pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tE6_WU4_Btx"
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSRC2iz5_IKx"
   },
   "outputs": [],
   "source": [
    "def knn_comparison(data, k):\n",
    "    x = data.iloc[:, 0:2].values\n",
    "    y = data.iloc[:, -1].astype(int).values\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(x, y)\n",
    "\n",
    "    plt.figure(figsize=(16,12))\n",
    "    plot_decision_regions(x, y, clf=knn)\n",
    "    plt.title(\"Knn with K=\"+ str(k), fontsize = 18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "executionInfo": {
     "elapsed": 1767,
     "status": "ok",
     "timestamp": 1603835977058,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "5oVhfFbFDt0z",
    "outputId": "a7e721a0-95b4-48fa-b660-cddfba13b818"
   },
   "outputs": [],
   "source": [
    "new = pd.concat([X,y],axis=1)\n",
    "new = new[['HV1','IC1','AVGGIFT']].sample(n=100,random_state=100)\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "executionInfo": {
     "elapsed": 3637,
     "status": "ok",
     "timestamp": 1603835982726,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -60
    },
    "id": "L69lIIRD_tHe",
    "outputId": "cb88f97d-099a-4ca3-b39a-ec86d91cf255"
   },
   "outputs": [],
   "source": [
    "# run the plot - be prepared this will look like crazy modern art\n",
    "knn_comparison(new,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2si8Xkk_WRb"
   },
   "source": [
    "### Activity - take time to look at the chart and reflect on the data\n",
    "What can you see in the plot? Try re running the cell to plot the data with a higher or lower k (1,2,4,9,15,30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2SxYSvx_mQD"
   },
   "source": [
    "#### explanation \n",
    "The lower the number of k the more over-fitted it will be. We can see that with k = 1, the boundaries are very clear and as we increase k the plots start turning very messy until the last two plots, where it is oversimplified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFk_Ju1FKEnN"
   },
   "source": [
    "# Metrics Review (Linear Regression):\n",
    "\n",
    "From all the regression metrics we have seen, which one(s) do you think you will use in most cases?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr4SrxE4KLbT"
   },
   "source": [
    "We have seen R2, MSE, RMSE and MAE. Of course, there is not a magic solution for which you should always use it, but there are some details worth knowing:\n",
    "\n",
    "*  R2 is scaled, which means that it is independent of the data. This one would be the one to go with if we don't know a lot about the data and general information about our model. However, it can be misleading, as it is supposed to be between 0 and 1 but sometimes it is not (you can read about it here. In fact, R2 is a biased estimator (more information here.\n",
    "\n",
    "*  MAE would be the median of the regression metrics as what it measures is the sum of distances between predicted and real values (errors), and that won't give a special treat to really bad predictions, so if that's what we want this metric should do great.\n",
    "\n",
    "*  MSE - It is the mean of the squared distance of the errors, which will weight the bad predictions.\n",
    "\n",
    "*  RMSE - Root MSE, essentially it is the same but it is easier to understand within the data context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity \n",
    "\n",
    "Focusing on either the linear or knn model it can be useful to calculate the R2 adjusted- read through the guide below and run the last cell to calculate the metric. Hint: you will need to refer to r2, so first you should set the parameter (hard code it) from one of the earlier model summary cells \n",
    "\n",
    "- r_squared = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 and R2-adjusted \n",
    "R2 shows how well terms (data points) fit a curve or line. Adjusted R2 also indicates how well terms fit a curve or line, but adjusts for the number of terms in a model. If you add more and more useless variables to a model, adjusted r-squared will decrease. If you add more useful variables, adjusted r-squared will increase.\n",
    "Adjusted R2 will always be less than or equal to R2.\n",
    "\n",
    "--------\n",
    "\n",
    "#### The adjusted R-squared is calculated as:\n",
    "\n",
    "Adjusted R2 = 1 – [(1-R2)*(n-1)/(n-k-1)]\n",
    "\n",
    "where:\n",
    "\n",
    "- R2: The R2 of the model\n",
    "- n: The number of observations\n",
    "- k: The number of predictor variables\n",
    "\n",
    "--------\n",
    "\n",
    "Both R2 and the adjusted R2 give you an idea of how many data points fall within the line of the regression equation. However, there is one main difference between R2 and the adjusted R2: R2 assumes that every single variable explains the variation in the dependent variable. The adjusted R2 tells you the percentage of variation explained by only the independent variables that actually affect the dependent variable.\n",
    "\n",
    "NOTE : You only need R2 when working with samples. In other words, R2 isn’t necessary when you have data from an entire population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3e97UWBJyrb"
   },
   "outputs": [],
   "source": [
    "#R2adj can be computed with python as:\n",
    "    \n",
    "score_adj = 1 - (1-r_squared)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP5iBJELRXbi1gWIU+E16RM",
   "name": "Unit_4_Day_3_morning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
